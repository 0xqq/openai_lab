{
  "dummy": {
    "problem": "CartPole-v0",
    "Agent": "dummy.Dummy",
    "Memory": "LinearMemory",
    "Policy": "EpsilonGreedyPolicy",
    "param": {}
  },
  "q_table": {
    "problem": "CartPole-v0",
    "Agent": "q_table.QTable",
    "Memory": "LinearMemory",
    "Policy": "EpsilonGreedyPolicy",
    "param": {
      "learning_rate": 0.01,
      "gamma": 0.99,
      "exploration_anneal_episodes": 200
    }
  },
  "dev_dqn": {
    "problem": "DevCartPole-v0",
    "Agent": "dqn.DQN",
    "Memory": "LinearMemoryWithForgetting",
    "Policy": "BoltzmannPolicy",
    "param": {
      "train_per_n_new_exp": 1,
      "learning_rate": 0.02,
      "gamma": 0.99,
      "hidden_layers_shape": [4],
      "hidden_layers_activation": "sigmoid",
      "state_preprocessing": null,
      "exploration_anneal_episodes": 10
    },
    "param_range": {
      "learning_rate": [0.01, 0.1]
    }
  },
  "dqn": {
    "problem": "CartPole-v0",
    "Agent": "dqn.DQN",
    "Memory": "LinearMemoryWithForgetting",
    "Policy": "BoltzmannPolicy",
    "param": {
      "train_per_n_new_exp": 1,
      "learning_rate": 0.02,
      "gamma": 0.99,
      "hidden_layers_shape": [4],
      "hidden_layers_activation": "sigmoid",
      "exploration_anneal_episodes": 10
    },
    "param_range": {
      "learning_rate": [0.01, 0.1],
      "gamma": [0.95, 0.99],
      "exploration_anneal_episodes": [10, 20]
    }
  },
  "double_dqn": {
    "problem": "CartPole-v0",
    "Agent": "double_dqn.DoubleDQN",
    "Memory": "LinearMemory",
    "Policy": "EpsilonGreedyPolicy",
    "param": {
      "train_per_n_new_exp": 1,
      "learning_rate": 0.01,
      "batch_size": 32,
      "gamma": 0.99,
      "hidden_layers_shape": [4],
      "hidden_layers_activation": "sigmoid",
      "exploration_anneal_episodes": 180
    }
  },
  "mountain_dqn": {
    "problem": "MountainCar-v0",
    "Agent": "lunar_dqn.LunarDQN",
    "Memory": "LinearMemoryWithForgetting",
    "Policy": "EpsilonGreedyPolicy",
    "param": {
      "train_per_n_new_exp": 4,
      "learning_rate": 0.001,
      "batch_size": 32,
      "gamma": 0.98,
      "hidden_layers_shape": [200, 100],
      "hidden_layers_activation": "relu",
      "exploration_anneal_episodes": 100
    },
    "param_range": {
      "learning_rate": [0.001, 0.01],
      "hidden_layers_shape": [
        [200, 100],
        [200, 100, 50]
      ]
    }
  },
  "mountain_double_dqn": {
    "problem": "MountainCar-v0",
    "Agent": "mountain_double_dqn.MountainDoubleDQN",
    "Memory": "LinearMemory",
    "Policy": "EpsilonGreedyPolicy",
    "param": {
      "train_per_n_new_exp": 1,
      "learning_rate": 0.01,
      "batch_size": 128,
      "gamma": 0.99,
      "hidden_layers_shape": [8, 8],
      "hidden_layers_activation": "sigmoid",
      "exploration_anneal_episodes": 300
    }
  },
  "lunar_dqn": {
    "problem": "LunarLander-v2",
    "Agent": "lunar_dqn.LunarDQN",
    "Memory": "LinearMemoryWithForgetting",
    "Policy": "EpsilonGreedyPolicy",
    "param": {
      "train_per_n_new_exp": 4,
      "learning_rate": 0.001,
      "batch_size": 32,
      "gamma": 0.99,
      "hidden_layers_shape": [200, 100],
      "hidden_layers_activation": "relu",
      "output_layer_activation": "linear",
      "state_preprocessing": "concat",
      "exploration_anneal_episodes": 300,
      "epi_change_learning_rate": 325
    },
    "param_range": {
      "train_per_n_new_exp": [1, 2, 3, 4, 5, 8, 10, 15],
      "gamma": [0.95, 0.96, 0.97, 0.98, 0.99],
      "exploration_anneal_episodes": [100, 200, 300, 400, 500, 600],
      "learning_rate": [0.01, 0.005, 0.001, 0.0005, 0.0001],
      "hidden_layers_shape": [
        [100],
        [200],
        [300],
        [400],
        [500],
        [200, 100],
        [300, 100],
        [300, 150],
        [400, 100],
        [400, 200]
      ]
    }
  },
  "lunar_double_dqn": {
    "problem": "LunarLander-v2",
    "Agent": "lunar_double_dqn.LunarDoubleDQN",
    "Memory": "LinearMemory",
    "Policy": "EpsilonGreedyPolicy",
    "param": {
      "train_per_n_new_exp": 1,
      "learning_rate": 0.01,
      "batch_size": 64,
      "gamma": 0.99,
      "hidden_layers_shape": [200, 100],
      "hidden_layers_activation": "relu",
      "exploration_anneal_episodes": 500
    }
  },
  "air_raid_dqn": {
    "problem": "AirRaid-v0",
    "Agent": "atari_conv_dqn.ConvDQN",
    "Memory": "LongLinearMemoryWithForgetting",
    "Policy": "EpsilonGreedyPolicy",
    "param": {
      "train_per_n_new_exp": 4,
      "learning_rate": 0.001,
      "batch_size": 32,
      "gamma": 0.99,
      "hidden_layers_shape": [
        [16, 8, 8, [4, 4]],
        [32, 4, 4, [2, 2]]
      ],
      "hidden_layers_activation": "relu",
      "state_preprocessing": "atari",
      "exploration_anneal_episodes": 1000000,
      "epi_change_learning_rate": 1000000
    },
    "param_range": {
      "learning_rate": [0.001, 0.01],
      "hidden_layers_shape": [
        [200, 100],
        [300, 200],
        [200, 100, 50]
      ]
    }
  },
  "breakout_dqn": {
    "problem": "Breakout-v0",
    "Agent": "atari_conv_dqn.ConvDQN",
    "Memory": "LongLinearMemoryWithForgetting",
    "Policy": "EpsilonGreedyPolicy",
    "param": {
      "train_per_n_new_exp": 4,
      "learning_rate": 0.001,
      "batch_size": 32,
      "gamma": 0.99,
      "hidden_layers_shape": [
        [16, 8, 8, [4, 4]],
        [32, 4, 4, [2, 2]]
      ],
      "hidden_layers_activation": "relu",
      "state_preprocessing": "atari",
      "exploration_anneal_episodes": 1000000,
      "epi_change_learning_rate": 1000000
    },
    "param_range": {
      "learning_rate": [0.001, 0.01],
      "hidden_layers_shape": [
        [200, 100],
        [300, 200],
        [200, 100, 50]
      ]
    }
  }
}

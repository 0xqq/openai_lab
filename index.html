<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <title>OpenAI Lab Doc</title>

    <style>
      .highlight table td { padding: 5px; }
.highlight table pre { margin: 0; }
.highlight {
  color: #faf6e4;
  background-color: #122b3b;
}
.highlight .gl {
  color: #dee5e7;
  background-color: #4e5d62;
}
.highlight .c, .highlight .cd, .highlight .cm, .highlight .c1, .highlight .cs {
  color: #6c8b9f;
  font-style: italic;
}
.highlight .cp {
  color: #b2fd6d;
  font-weight: bold;
  font-style: italic;
}
.highlight .err {
  color: #fefeec;
  background-color: #cc0000;
}
.highlight .gr {
  color: #fefeec;
  background-color: #cc0000;
}
.highlight .k, .highlight .kd, .highlight .kv {
  color: #f6dd62;
  font-weight: bold;
}
.highlight .o, .highlight .ow {
  color: #4df4ff;
}
.highlight .p, .highlight .pi {
  color: #4df4ff;
}
.highlight .gd {
  color: #cc0000;
}
.highlight .gi {
  color: #b2fd6d;
}
.highlight .ge {
  font-style: italic;
}
.highlight .gs {
  font-weight: bold;
}
.highlight .gt {
  color: #dee5e7;
  background-color: #4e5d62;
}
.highlight .kc {
  color: #f696db;
  font-weight: bold;
}
.highlight .kn {
  color: #ffb000;
  font-weight: bold;
}
.highlight .kp {
  color: #ffb000;
  font-weight: bold;
}
.highlight .kr {
  color: #ffb000;
  font-weight: bold;
}
.highlight .gh {
  color: #ffb000;
  font-weight: bold;
}
.highlight .gu {
  color: #ffb000;
  font-weight: bold;
}
.highlight .kt {
  color: #b2fd6d;
  font-weight: bold;
}
.highlight .no {
  color: #b2fd6d;
  font-weight: bold;
}
.highlight .nc {
  color: #b2fd6d;
  font-weight: bold;
}
.highlight .nd {
  color: #b2fd6d;
  font-weight: bold;
}
.highlight .nn {
  color: #b2fd6d;
  font-weight: bold;
}
.highlight .bp {
  color: #b2fd6d;
  font-weight: bold;
}
.highlight .ne {
  color: #b2fd6d;
  font-weight: bold;
}
.highlight .nl {
  color: #ffb000;
  font-weight: bold;
}
.highlight .nt {
  color: #ffb000;
  font-weight: bold;
}
.highlight .m, .highlight .mf, .highlight .mh, .highlight .mi, .highlight .il, .highlight .mo, .highlight .mb, .highlight .mx {
  color: #f696db;
  font-weight: bold;
}
.highlight .ld {
  color: #f696db;
  font-weight: bold;
}
.highlight .ss {
  color: #f696db;
  font-weight: bold;
}
.highlight .s, .highlight .sb, .highlight .sd, .highlight .s2, .highlight .sh, .highlight .sx, .highlight .sr, .highlight .s1 {
  color: #fff0a6;
  font-weight: bold;
}
.highlight .se {
  color: #4df4ff;
  font-weight: bold;
}
.highlight .sc {
  color: #4df4ff;
  font-weight: bold;
}
.highlight .si {
  color: #4df4ff;
  font-weight: bold;
}
.highlight .nb {
  font-weight: bold;
}
.highlight .ni {
  color: #999999;
  font-weight: bold;
}
.highlight .w {
  color: #BBBBBB;
}
.highlight .nf {
  color: #a8e1fe;
}
.highlight .py {
  color: #a8e1fe;
}
.highlight .na {
  color: #a8e1fe;
}
.highlight .nv, .highlight .vc, .highlight .vg, .highlight .vi {
  color: #a8e1fe;
  font-weight: bold;
}
    </style>
    <link href="stylesheets/screen.css" rel="stylesheet" media="screen" />
    <link href="stylesheets/print.css" rel="stylesheet" media="print" />
      <script src="javascripts/all.js"></script>
  </head>

  <body class="index" data-languages="[&quot;python&quot;]">
    <a href="#" id="nav-button">
      <span>
        NAV
        <img src="images/navbar.png" alt="Navbar" />
      </span>
    </a>
    <div class="tocify-wrapper">
      <img src="images/logo.png" alt="Logo" />
        <div class="lang-selector">
              <a href="#" data-language-name="python">python</a>
        </div>
        <div class="search">
          <input type="text" class="search" id="input-search" placeholder="Search">
        </div>
        <ul class="search-results"></ul>
      <div id="toc">
      </div>
        <ul class="toc-footer">
            <li><a href='https://github.com/kengz/openai_lab'>OpenAI Lab Github</a></li>
            <li><a href='https://github.com/openai/gym'>OpenAI Gym Github</a></li>
        </ul>
    </div>
    <div class="page-wrapper">
      <div class="dark-box"></div>
      <div class="content">
        <h1 id="openai-lab">OpenAI Lab <a href="https://circleci.com/gh/kengz/openai_lab"><img src="https://circleci.com/gh/kengz/openai_lab.svg?style=shield" alt="CircleCI" /></a> <a href="https://www.codacy.com/app/kengzwl/openai_lab?utm_source=github.com&amp;amp;utm_medium=referral&amp;amp;utm_content=kengz/openai_lab&amp;amp;utm_campaign=Badge_Grade"><img src="https://api.codacy.com/project/badge/Grade/a0e6bbbb6c4845ccaab2db9aecfecbb0" alt="Codacy Badge" /></a></h1>

<p><strong>(DOC UNDER CONSTRUCTION)</strong></p>

<p><em>An experimentation system for Reinforcement Learning using OpenAI and Keras.</em></p>

<p>This lab is created to let us do Reinforcement Learning (RL) like science - <em>theorize, experiment</em>. We can theorize as fast as we think, and experiment as fast as the computers can run.</p>

<p>With <em>OpenAI Lab</em>, we had solved a few OpenAI environments by running dozens of experiments, each with hundreds of trials. Each new experiment takes minimal effort to setup and run - we will show by example below.</p>

<p>Before this, experiments used to be hard and slow, because we often have to write most things from scratch and reinvent the wheels. To solve this, the lab provides a standard, extensible platform with a host of reusable components.</p>

<p><em>OpenAI Lab</em> lowers the experimental complexity and enables an explosion of experiments - we can quickly add new RL component, make new combinations, run hyperparameter selection and solve the environments. This unlocks a new perspective to treat RL as a full-on experimental science.</p>

<p><img alt="Timelapse of OpenAI Lab" src="./images/lab_demo_dqn.gif" />
<em>Timelapse of OpenAI Lab (open the gif in new tab for larger size).</em></p>

<h2 id="lab-demo">Lab Demo</h2>

<p>Each experiment involves:
- a problem - an <a href="https://gym.openai.com/envs">OpenAI Gym environment</a>
- a RL agent with modular components <code class="prettyprint">agent, memory, optimizer, policy, preprocessor</code>, each of which is an experimental variable.</p>

<p>We specify input parameters for the experimental variable, run the experiment, record and analyze the data, conclude if the agent solves the problem with high rewards.</p>

<h3 id="specify-experiment">Specify Experiment</h3>

<p>The example below is fully specified in <code class="prettyprint">rl/asset/experiment_specs.json</code> under <code class="prettyprint">dqn</code>:</p>
<pre class="highlight json"><code><span class="p">{</span><span class="w">
  </span><span class="s2">"dqn"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="s2">"problem"</span><span class="p">:</span><span class="w"> </span><span class="s2">"CartPole-v0"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Agent"</span><span class="p">:</span><span class="w"> </span><span class="s2">"DQN"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"HyperOptimizer"</span><span class="p">:</span><span class="w"> </span><span class="s2">"GridSearch"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Memory"</span><span class="p">:</span><span class="w"> </span><span class="s2">"LinearMemoryWithForgetting"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Optimizer"</span><span class="p">:</span><span class="w"> </span><span class="s2">"AdamOptimizer"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Policy"</span><span class="p">:</span><span class="w"> </span><span class="s2">"BoltzmannPolicy"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"PreProcessor"</span><span class="p">:</span><span class="w"> </span><span class="s2">"NoPreProcessor"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"param"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="s2">"train_per_n_new_exp"</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w">
      </span><span class="s2">"lr"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.001</span><span class="p">,</span><span class="w">
      </span><span class="s2">"gamma"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.96</span><span class="p">,</span><span class="w">
      </span><span class="s2">"hidden_layers_shape"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mi">16</span><span class="p">],</span><span class="w">
      </span><span class="s2">"hidden_layers_activation"</span><span class="p">:</span><span class="w"> </span><span class="s2">"sigmoid"</span><span class="p">,</span><span class="w">
      </span><span class="s2">"exploration_anneal_episodes"</span><span class="p">:</span><span class="w"> </span><span class="mi">20</span><span class="w">
    </span><span class="p">},</span><span class="w">
    </span><span class="s2">"param_range"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="s2">"lr"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mf">0.001</span><span class="p">,</span><span class="w"> </span><span class="mf">0.01</span><span class="p">,</span><span class="w"> </span><span class="mf">0.02</span><span class="p">,</span><span class="w"> </span><span class="mf">0.05</span><span class="p">],</span><span class="w">
      </span><span class="s2">"gamma"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mf">0.95</span><span class="p">,</span><span class="w"> </span><span class="mf">0.96</span><span class="p">,</span><span class="w"> </span><span class="mf">0.97</span><span class="p">,</span><span class="w"> </span><span class="mf">0.99</span><span class="p">],</span><span class="w">
      </span><span class="s2">"hidden_layers_shape"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
        </span><span class="p">[</span><span class="mi">8</span><span class="p">],</span><span class="w">
        </span><span class="p">[</span><span class="mi">16</span><span class="p">],</span><span class="w">
        </span><span class="p">[</span><span class="mi">32</span><span class="p">]</span><span class="w">
      </span><span class="p">],</span><span class="w">
      </span><span class="s2">"exploration_anneal_episodes"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="w"> </span><span class="mi">20</span><span class="p">]</span><span class="w">
    </span><span class="p">}</span><span class="w">
  </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre>
<ul>
<li><em>experiment</em>: <code class="prettyprint">dqn</code></li>
<li><em>problem</em>: <a href="https://gym.openai.com/envs/CartPole-v0">CartPole-v0</a></li>
<li><em>variable agent component</em>: <code class="prettyprint">Boltzmann</code> policy</li>
<li><em>control agent variables</em>:

<ul>
<li><code class="prettyprint">DQN</code> agent</li>
<li><code class="prettyprint">LinearMemoryWithForgetting</code></li>
<li><code class="prettyprint">AdamOptimizer</code></li>
<li><code class="prettyprint">NoPreProcessor</code></li>
</ul></li>
<li><em>parameter variables values</em>: the <code class="prettyprint">&quot;param_range&quot;</code> JSON</li>
</ul>

<p>An <strong>experiment</strong> will run a trial for each combination of <code class="prettyprint">param</code> values; each <strong>trial</strong> will run for multiple repeated <strong>sessions</strong>. For <code class="prettyprint">dqn</code>, there are <code class="prettyprint">96</code> param combinations (trials), and <code class="prettyprint">5</code> repeated sessions per trial. Overall, this experiment will run <code class="prettyprint">96 x 5 = 480</code> sessions.</p>

<h3 id="lab-workflow">Lab Workflow</h3>

<p>The workflow to setup this experiment is as follow:</p>

<ol>
<li>Add the new theorized component <code class="prettyprint">Boltzmann</code> in <code class="prettyprint">rl/policy/boltzmann.py</code></li>
<li>Specify <code class="prettyprint">dqn</code> experiment spec in <code class="prettyprint">experiment_spec.json</code> to include this new variable,  reuse the other existing RL components, and specify the param range.</li>
<li>Add this experiment to the lab queue in <code class="prettyprint">config/production.json</code></li>
<li>Run <code class="prettyprint">grunt -prod</code></li>
<li>Analyze the graphs and data (live-synced)</li>
</ol>

<h3 id="lab-results">Lab Results</h3>

<p><img alt="The dqn experiment analytics" src="./images/dqn.png" />
<em>The dqn experiment analytics generated by the lab (open in new tab for larger size). This is a pairplot, where we isolate each variable, flatten the others, plot each trial as a point. The darker the color the higher ratio of the repeated sessions the trial solves.</em></p>

<table><thead>
<tr>
<th style="text-align: left">performance_score</th>
<th style="text-align: left">mean_rewards_per_epi_stats_mean</th>
<th style="text-align: left">mean_rewards_stats_mean</th>
<th style="text-align: left">epi_stats_mean</th>
<th style="text-align: left">solved_ratio_of_sessions</th>
<th style="text-align: left">num_of_sessions</th>
<th style="text-align: left">max_total_rewards_stats_mean</th>
<th style="text-align: left">t_stats_mean</th>
<th style="text-align: left">trial_id</th>
<th style="text-align: left">variable_exploration_anneal_episodes</th>
<th style="text-align: left">variable_gamma</th>
<th style="text-align: left">variable_hidden_layers_shape</th>
<th style="text-align: left">variable_lr</th>
</tr>
</thead><tbody>
<tr>
<td style="text-align: left">1.39203</td>
<td style="text-align: left">2.32005</td>
<td style="text-align: left">171.7815</td>
<td style="text-align: left">120.0</td>
<td style="text-align: left">0.6</td>
<td style="text-align: left">5</td>
<td style="text-align: left">200.0</td>
<td style="text-align: left">189.8</td>
<td style="text-align: left">dqn-2017_02_21_182442_t46</td>
<td style="text-align: left">10</td>
<td style="text-align: left">0.99</td>
<td style="text-align: left">[32]</td>
<td style="text-align: left">0.02</td>
</tr>
<tr>
<td style="text-align: left">1.239977</td>
<td style="text-align: left">1.239977</td>
<td style="text-align: left">195.272</td>
<td style="text-align: left">167.2</td>
<td style="text-align: left">1.0</td>
<td style="text-align: left">5</td>
<td style="text-align: left">200.0</td>
<td style="text-align: left">199.0</td>
<td style="text-align: left">dqn-2017_02_21_182442_t45</td>
<td style="text-align: left">10</td>
<td style="text-align: left">0.99</td>
<td style="text-align: left">[32]</td>
<td style="text-align: left">0.01</td>
</tr>
<tr>
<td style="text-align: left">1.196581</td>
<td style="text-align: left">1.196581</td>
<td style="text-align: left">195.372</td>
<td style="text-align: left">168.0</td>
<td style="text-align: left">1.0</td>
<td style="text-align: left">5</td>
<td style="text-align: left">200.0</td>
<td style="text-align: left">199.0</td>
<td style="text-align: left">dqn-2017_02_21_182442_t80</td>
<td style="text-align: left">20</td>
<td style="text-align: left">0.97</td>
<td style="text-align: left">[32]</td>
<td style="text-align: left">0.001</td>
</tr>
<tr>
<td style="text-align: left">1.192967</td>
<td style="text-align: left">1.192967</td>
<td style="text-align: left">196.102</td>
<td style="text-align: left">165.4</td>
<td style="text-align: left">1.0</td>
<td style="text-align: left">5</td>
<td style="text-align: left">200.0</td>
<td style="text-align: left">199.0</td>
<td style="text-align: left">dqn-2017_02_21_182442_t68</td>
<td style="text-align: left">20</td>
<td style="text-align: left">0.96</td>
<td style="text-align: left">[32]</td>
<td style="text-align: left">0.001</td>
</tr>
<tr>
<td style="text-align: left">1.191591</td>
<td style="text-align: left">1.191591</td>
<td style="text-align: left">195.49</td>
<td style="text-align: left">166.2</td>
<td style="text-align: left">1.0</td>
<td style="text-align: left">5</td>
<td style="text-align: left">200.0</td>
<td style="text-align: left">195.0</td>
<td style="text-align: left">dqn-2017_02_21_182442_t28</td>
<td style="text-align: left">10</td>
<td style="text-align: left">0.97</td>
<td style="text-align: left">[16]</td>
<td style="text-align: left">0.001</td>
</tr>
</tbody></table>

<p><em>Analysis data table, top 5 trials.</em></p>

<p>On completion, from the analytics (zoom on the graph), we conclude that the experiment is a success, and the best agent that solves the problem has the parameters:</p>

<ul>
<li><em>lr</em>: 0.1</li>
<li><em>gamma</em>: 0.99</li>
<li><em>hidden_layers_shape</em>: [32]</li>
<li><em>exploration_anneal_episodes</em>: 10</li>
</ul>

<h3 id="run-your-own-lab">Run Your Own Lab</h3>

<p>Want to run the lab? Go to <a href="#installation">Installation</a>, <a href="#Usage">Usage</a> and <a href="#development">Development</a>.</p>

          <h1 id="installation"><a name="installation"></a>Installation</h1>

<p>1. Run the setup script:</p>
<pre class="highlight shell"><code>git clone https://github.com/kengz/openai_lab.git
<span class="nb">cd </span>openai_lab
./bin/setup
</code></pre>
<p><code class="prettyprint">bin/setup</code> installs all the dependencies the same way as our servers and <a href="https://circleci.com/gh/kengz/openai_lab">CircleCI builds</a>; inspect or change it as needed.</p>

<p>2. Keras needs a backend in the home directory; setup your <code class="prettyprint">~/.keras/keras.json</code> using example file in <code class="prettyprint">config/keras.json</code>.</p>
<pre class="highlight json"><code><span class="p">{</span><span class="w">
  </span><span class="s2">"epsilon"</span><span class="p">:</span><span class="w"> </span><span class="mi">1e-07</span><span class="p">,</span><span class="w">
  </span><span class="s2">"image_dim_ordering"</span><span class="p">:</span><span class="w"> </span><span class="s2">"tf"</span><span class="p">,</span><span class="w">
  </span><span class="s2">"floatx"</span><span class="p">:</span><span class="w"> </span><span class="s2">"float32"</span><span class="p">,</span><span class="w">
  </span><span class="s2">"backend"</span><span class="p">:</span><span class="w"> </span><span class="s2">"tensorflow"</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre>
<aside class="notice">
We recommend Tensorflow for experimentation with multi-GPU for stability. By default <code>bin/setup</code> will install <code>tensorflow</code> for MacOS and <code>tensorflow-gpu</code> for Linux.
Use Theano once your lab produces a final model for a single retraining, since it&rsquo;s faster.
</aside>

<p>3. <code class="prettyprint">bin/setup</code> also creates the needed config files needed for lab <a href="#usage">usage</a>. See sections below for more info.</p>

<ul>
<li><code class="prettyprint">config/default.json</code> for local development, used when <code class="prettyprint">grunt</code> is ran without a production flag.</li>
<li><code class="prettyprint">config/production.json</code> for production lab run when <code class="prettyprint">grunt -prod</code> is ran with the production flag <code class="prettyprint">-prod</code></li>
</ul>
<pre class="highlight json"><code><span class="p">{</span><span class="w">
  </span><span class="s2">"data_sync_destination"</span><span class="p">:</span><span class="w"> </span><span class="s2">"~/Dropbox/openai_lab/data"</span><span class="p">,</span><span class="w">
  </span><span class="s2">"NOTI_SLACK_DEST"</span><span class="p">:</span><span class="w"> </span><span class="s2">"#rl-monitor"</span><span class="p">,</span><span class="w">
  </span><span class="s2">"NOTI_SLACK_TOK"</span><span class="p">:</span><span class="w"> </span><span class="s2">"GET_SLACK_BOT_TOKEN_FROM_https://my.slack.com/services/new/bot"</span><span class="p">,</span><span class="w">
  </span><span class="s2">"experiments"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="s2">"dev_dqn"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"dqn"</span><span class="w">
  </span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre>
<h2 id="setup-data-auto-sync">Setup Data Auto-sync</h2>

<p>We find it extremely useful to have data file sync when running the lab on a remote server. This allows us to have a live view of the experiment graphs and data on our Dropbox app on a computer or a smartphone.</p>

<p>For auto-syncing lab <code class="prettyprint">data/</code> we use <a href="http://gruntjs.com/">Grunt</a> file watcher for automatically copying data files via Dropbox. In your dropbox, set up a shared folder <code class="prettyprint">~/Dropbox/openai_lab/data</code> and sync to desktop.</p>

<aside class="notice">
Setup the config key <code>data_sync_destination</code> in <code>config/{default.json, production.json}</code>.
</aside>

<h2 id="setup-auto-notification">Setup Auto-notification</h2>

<p>Experiments take a while to run, and we find it useful also to be notified automatically when it&rsquo;s complete. We use <a href="https://github.com/variadico/noti">noti</a>, which is also installed with <code class="prettyprint">bin/setup</code>.</p>

<p>Set up a Slack, create a new channel <code class="prettyprint">#rl_monitor</code>, and get a <a href="https://my.slack.com/services/new/bot">Slack bot token</a>.</p>

<aside class="notice">
Setup the config keys <code>NOTI_SLACK_DEST</code>, <code>NOTI_SLACK_TOK</code> in <code>config/{default.json, production.json}</code>.
</aside>

<p><img alt="Notifications from the lab running on our remote server beast" src="./images/noti.png" />
<em>Notifications from the lab running on our remote server beast.</em></p>

<h2 id="setup-experiments">Setup Experiments</h2>

<p>There are many existing experiments specified in <code class="prettyprint">rl/asset/experiment_specs.json</code>, and you can add more. Pick the <code class="prettyprint">experiment_name</code>s (the JSON key, e.g. <code class="prettyprint">&quot;dqn&quot;, &quot;lunar_dqn&quot;</code>), list under config key <code class="prettyprint">experiment</code>. Then check <a href="#usage">usage</a> to run the lab.</p>

          <h1 id="usage"><a name="usage"></a>Usage</h1>

<p>The general flow for running a production lab is:</p>

<ol>
<li>Specify experiments in <code class="prettyprint">rl/asset/experiment_specs.json</code>, e.g. <code class="prettyprint">&quot;dqn&quot;, &quot;lunar_dqn&quot;</code></li>
<li>Specify the names of the experiments to run in <code class="prettyprint">config/production.json</code></li>
<li>Run the lab, e.g. <code class="prettyprint">grunt -prod -resume</code></li>
</ol>

<h2 id="commands">Commands</h2>

<p>We use <a href="http://gruntjs.com/">Grunt</a> to run the lab - set up experiments, pause/resume lab, run analyses, sync data, notify on completion. Internally <code class="prettyprint">grunt</code> runs the <code class="prettyprint">python</code> command, which is harder to use, but we will include the <a href="#python-cmd">details below for reference</a>.</p>

<p>The useful grunt commands are:</p>
<pre class="highlight shell"><code><span class="c"># when developing experiments specified in default.json</span>
grunt

<span class="c"># run real lab experiments specified in production.json</span>
grunt -prod
<span class="c"># run lab over ssh on remote server</span>
grunt -prod -remote
<span class="c"># resume lab (previously incomplete experiments)</span>
grunt -prod -remote -resume

<span class="c"># plot analysis graphs only</span>
grunt analyze -prod

<span class="c"># clear data/ folder and cache files</span>
grunt clear
</code></pre>
<p><strong>development</strong> mode:</p>

<ul>
<li>All grunt commands defaults to this mode</li>
<li>specify your dev experiment in <code class="prettyprint">config/default.json</code></li>
<li>use only when developing your new algo</li>
<li>the file-sync is in mock mode (emulated log without real file copying)</li>
<li>no auto-notification</li>
</ul>

<p><strong>production</strong> mode:</p>

<ul>
<li>append the flag <code class="prettyprint">-prod</code> to your <code class="prettyprint">grunt</code> command</li>
<li>specify your full experiments in <code class="prettyprint">config/production.json</code></li>
<li>use when running experiments for real</li>
<li>the file-sync is real</li>
<li>has auto-notification to Slack channel</li>
</ul>

<h3 id="run-remotely">Run Remotely</h3>

<p>If you&rsquo;re using a remote server, run the commands inside a <code class="prettyprint">screen</code>. That is, log in via ssh, start a screen, run, then detach screen.</p>
<pre class="highlight shell"><code>screen -S lab
<span class="c"># enter the screen with the name "lab"</span>
grunt -prod -remote -resume
<span class="c"># use Cmd+A+D to detach from screen, then Cmd+D to disconnect ssh</span>
<span class="c"># to resume screen next time</span>
screen -r lab
<span class="c"># use Cmd+D to terminate screen when lab ends</span>
</code></pre>
<p>Since a remote server is away, you should check the system status occasionally to ensure no overrunning processes (memory leaks, stuck processes, overheating). Use <a href="https://github.com/nicolargo/glances"><code class="prettyprint">glances</code></a> (already installed in <code class="prettyprint">bin/setup</code>) to monitor your expensive machines.</p>

<aside class="notice">
To monitor your system (CPU, RAM, GPU), run <code>glances</code>
</aside>

<p><img alt="Glances to monitor your system" src="./images/glances.png" />
<em>Glances on remote server beast.</em></p>

<h3 id="resume-lab">Resume Lab</h3>

<p>Experiments take a long time to complete, and if your process gets terminated, resuming the lab is trivial with a <code class="prettyprint">-resume</code> flag: <code class="prettyprint">grunt -prod -remote -resume</code>. This will read the <code class="prettyprint">config/history.json</code>:</p>
<pre class="highlight json"><code><span class="p">{</span><span class="w">
  </span><span class="s2">"dqn"</span><span class="p">:</span><span class="w"> </span><span class="s2">"dqn-2017_02_21_182442"</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre>
<p>The <code class="prettyprint">config/history.json</code> is created in the last run that maps <code class="prettyprint">experiment_name</code>s to <code class="prettyprint">experiment_id</code>s, and resume any incomplete experiments based on that <code class="prettyprint">experiment_id</code>. You can manually tweak the file to set the resume target of course.</p>

<h3 id="grunt-command-details">Grunt Command Details</h3>

<p>By default the <code class="prettyprint">grunt</code> command (no task or flag) runs the lab in <code class="prettyprint">development</code> mode using <code class="prettyprint">config/default.json</code>.</p>

<p>The basic grunt command pattern is</p>
<pre class="highlight shell"><code>grunt &lt;task&gt; -&lt;flag&gt;
</code></pre>
<p>The <code class="prettyprint">&lt;task&gt;</code>s are:</p>

<ul>
<li><em>(default empty)</em>: run the lab</li>
<li><code class="prettyprint">analyze</code>: generate analysis data and graphs only, without running the lab. This can be used when you wish to see the analysis results midway during a long-running experiment. Run it on a separate terminal window as <code class="prettyprint">grunt analyze -prod</code></li>
<li><code class="prettyprint">clear</code>: clear the <code class="prettyprint">data/</code> folder and cache files. <strong>Be careful</strong> and make sure your data is already copied to the sync location</li>
</ul>

<p>The <code class="prettyprint">&lt;flag&gt;</code>s are:</p>

<ul>
<li><code class="prettyprint">-prod</code>: production mode, use <code class="prettyprint">config/production.json</code></li>
<li><code class="prettyprint">-resume</code>: resume incomplete experiments from <code class="prettyprint">config/history.json</code></li>
<li><code class="prettyprint">-remote</code>: when running over SSH, supplies this to use a fake display</li>
<li><code class="prettyprint">-best</code>: run the finalized experiments with gym rendering and live plotting; without param selection. This uses the default <code class="prettyprint">param</code> in <code class="prettyprint">experiment_specs.json</code> that shall be updated to the best found.</li>
<li><code class="prettyprint">-quiet</code>: mute all python logging in grunt. This is for lab-level development only.</li>
</ul>

<h3 id="internal-python-command"><a name="python-cmd"></a>Internal Python command</h3>

<p>The Python command is invoked inside <code class="prettyprint">Gruntfile.js</code> under the <code class="prettyprint">composeCommand</code> function. Change it if you need to.</p>

<p>The basic python command pattern is:</p>
<pre class="highlight shell"><code>python3 main.py -&lt;flag&gt;

<span class="c"># most common example, with piping of terminal log</span>
python3 main.py -gbp -t 5 -e lunar_dqn | tee -a ./data/terminal.log;
</code></pre>
<p>The python command <flag>s are:</p>

<ul>
<li><code class="prettyprint">-a</code>: Run <code class="prettyprint">analyze_experiment()</code> only to plot <code class="prettyprint">experiment_data</code>. Default: <code class="prettyprint">False</code></li>
<li><code class="prettyprint">-b</code>: blind mode, do not render graphics. Default: <code class="prettyprint">False</code></li>
<li><code class="prettyprint">-d</code>: log debug info. Default: <code class="prettyprint">False</code></li>
<li><code class="prettyprint">-q</code>: quiet mode, log warning only. Default: <code class="prettyprint">False</code></li>
<li><code class="prettyprint">-e &lt;experiment&gt;</code>: specify which of <code class="prettyprint">rl/asset/experiment_spec.json</code> to run. Default: <code class="prettyprint">-e dev_dqn</code>. Can be a <code class="prettyprint">experiment_name, experiment_id</code>.</li>
<li><code class="prettyprint">-g</code>: plot graphs live. Default: <code class="prettyprint">False</code></li>
<li><code class="prettyprint">-m &lt;max_evals&gt;</code>: the max number of trials for hyperopt. Default: <code class="prettyprint">100</code></li>
<li><code class="prettyprint">-p</code>: run param selection. Default: <code class="prettyprint">False</code></li>
<li><code class="prettyprint">-t &lt;times&gt;</code>: the number of sessions to run per trial. Default: <code class="prettyprint">1</code></li>
<li><code class="prettyprint">-x &lt;max_episodes&gt;</code>: Manually specifiy max number of episodes per trial. Default: <code class="prettyprint">-1</code> and program defaults to value in <code class="prettyprint">rl/asset/problems.json</code></li>
</ul>

          <h1 id="features"><a name="features"></a>Features</h1>

          <h1 id="development"><a name="development"></a>Development</h1>

          <h1 id="roadmap"><a name="roadmap"></a>Roadmap</h1>

          <h1 id="contributing"><a name="contributing"></a>Contributing</h1>

<h2 id="authors">Authors</h2>

<p><em>Note: we are not affiliated with OpenAI</em></p>

<ul>
<li>Wah Loon Keng</li>
<li>Laura Graesser</li>
</ul>

      </div>
      <div class="dark-box">
          <div class="lang-selector">
                <a href="#" data-language-name="python">python</a>
          </div>
      </div>
    </div>
  </body>
</html>
